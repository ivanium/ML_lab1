# Intro to ML Experiment 1: Naive Bayes

计54 乔一凡 2015011398

## 一 实验概述

### 1. 问题定义

* 数据集描述

  本次实验我们使用的数据集为分词后的 TREC-06 中文邮件数据集，大小为 64620。所有数据以 UTF-8 文本形式给出，并通过 spam/ham 标注。数据中包含邮件的 metadata 和邮件的经过分词后的正文内容。

* 实现目标

  我们的模型 E 在给定的训练集数据 TS 上经过训练后，应当能够对模型 E 未见过的相同格式数据 D 利用训练过的参数预测 D 对应的邮件是/不是垃圾邮件的概率，并最终在我们的测试集上达到一个较好的效果 P。

  在对结果进行评价的方面，效果 P 可以有多种定义，如准确率（预测正确的样本占总测试集的比例），precision，recall，以及通过 precision 和 recall 计算出的 F1值。

### 2. 实现原理

本次实验我们使用 Naive Bayes 分类器，其原理基于 Bayes 公式。若计邮件是否为垃圾邮件为随机变量 $Y = \{spam, ham\}$ ，邮件正文分词后的词数量为随机变量 $N = n$，对应的词分别为随机变量 $X_1,X_2,…X_n$，则公式可以表示如下：
$$
P(Y=y|X_1=x_1,X_2=x_2,...,X_n=x_n) = \frac{P(X_1=x_1,X_2=x_2,...,X_n=x_n| Y=y)\cdot P(Y=y)}{P(X_1=x_1,X_2=x_2,...,X_n=x_n)}
$$
根据问题定义，本次实验的目标就是在已知一封邮件的正文分词结果后，给出该邮件是垃圾邮件的条件概率，也就是上述公式的左侧部分。为此，我们需要通过模型在训练集上的训练估计出公式右边的各个部分的估计值。

由于公式的结构很复杂，不易直接训练估计，为了简化问题，我们作如下假设：

* 一封邮件为垃圾邮件仅与其正文中出现的词具体取值有关，而与词的位置，顺序无关。这样所有的词随机变量 $X_i$ 意义均相同；
* 在一封邮件正文中出现的所有词随机变量 $X_i$ 间相互独立，且这些词随机变量均与邮件正文分词数量随机变量 $N$ 相互独立，即：

$$
\forall i,j \in [1, n], P(X_iX_j) = P(X_i)P(X_j) \\
\forall i \in [1,n], P(X_iN) = P(X_i)P(N)
$$

由此我们可以将之前的 Bayes 公式简化为如下形式：
$$
P(Y|X_1,X_2,...,X_n) = \frac{\prod\limits_{i=1}^n P(X_i| Y)\cdot P(Y)}{\prod\limits_{i=1}^nP(X_i)}
$$
注意到 $\prod\limits_{i=1}^n P(X_i)$ 对于 $Y$ 而言在给定数据集上是一个常数，与 Y 的取值无关，可以略去而不影响最终的结果。故最终公式简化为：
$$
P(Y|X_1,X_2,...,X_n) \propto \prod\limits_{i=1}^n P(X_i| Y)\cdot P(Y)
$$
使用大数定律估计公式右侧需要的概率：
$$
P(Y = \{spam/ham\}) \approx \frac{\# \{spam/ham\}\ in\ train\ set}{\#train\ set\ size} \\
P(X_i = x_i| Y = \{spam/ham\}) \approx \frac{\# word\ x_i\ in\ all\ \{\ spam/ham\}}{\# total\ words\ in\ \{spam/ham\}\ }
$$
由此我们可以估算出 $P(Y = spam|X_1,X_2,...,X_n) $ 和 $P(Y = ham|X_1,X_2,...,X_n) $，又 $P(Y = spam|X_1,X_2,...,X_n) + P(Y=ham|X_1,X_2,...,X_n) = 1$，我们将这两个概率归一化即可得到对邮件的预测。

## 二 实现概述

主要的实现被封装在 `class SpamFilter` 中。

在类的构造函数中定义好了类的有关成员变量，一些设定的参数（包括平滑系数，训练集占数据集的比例等等）并对参数做相应的初始化。默认设置训练集占数据集 80%，测试集占数据集的 20%；平滑系数 laplace = 1e-10。

数据的读入处理由函数 `load_data()` 完成，该函数也会完成数据的持久化部分。

对邮件正文的解析处理由函数 `parse_mail()` 完成。函数会根据是否 predict 进行训练或者预测，训练时会将读到的词加入模型维护的词典。在实现中我认为由于是中文邮件分类，很多数字，标点会造成信息的冗余，增大噪声，因此在实现中将所有的非中文分词滤掉，只统计中文词。每个词的词频通过字典维护。

对邮件数据头部的 metadata 的解析由函数 `parse_head()` 完成。在本实验中主要实现了对邮件发件地址的提取统计。

预测功能由 `predict()` 函数实现。函数调用 parse 系列函数获得测试集中每封邮件是否垃圾邮件的概率，并最终汇总统计得到结果。为了避免计算概率连乘时由于每个概率都很小导致最终结果下溢，统一对概率取对数，变连乘为连加求和。

## 三 问题解答

### 1. 训练集大小对结果的影响

* 理论分析

  根据伯努利大数定律，训练集样本越大，我们对概率的估计就越准确。因此，当训练集大小过小的时候，我们对概率的估计就越不准确，最终导致我们在测试集上的准确率下降， 效果变差。

  同时，当我们的训练集大小过小的时候，模型中记录的单词种类数也会相应变少。这一方面会导致零概率（如 Issue 2 中描述）的情况增加，另一方面导致最终可用于预测的单词数减少，这会导致我们用于预测的信息减少，会导致最终的预测效果变差。

* 实验设计

  实验中训练集划分均为全部数据的 80% 作为训练集，其余 20% 作为测试集（下同，不再赘述）。

  通过对训练集使用不同的采样率进行采样可以获得不同大小的训练集。本次实验中选择 5 个典型的采样率：1%, 5%, 25%, 50%, 100%，分别随机采样五次后统计其平均/最高/最低准确率和标准差。

* 实验结果

  | 采样率 / % | 最高准确率 | 最低准确率 | 平均准确率 | 标准差 |
  | ------ | ---------- | ---------- | ---------- | ------ |
  | 1 | 0.9581 | 0.9465 | 0.9533 | 4.51e-3 |
  | 5 | 0.9726 | 0.9653 | 0.9687 |2.37e-3|
  | 25 | 0.9750 | 0.9690 | 0.9718 |2.00e-3|
  | 50 | **0.9776** | 0.9728 | **0.9745** |1.80e-3|
  | 100 | 0.9745 | **0.9745** | **0.9745** |0|

  **PR-Curve with different sample rate：**

  ![sample](/Users/ivanium/learn/3d/ML/lab1/sample.png)

  分析：

  可以看到最终预测的准确率与采样率间有较强的相关关系。体现在以下几个方面：

  * 虽然不同采样率下最终的平均准确率均较高，在95%以上，但是很明显地随着采样率的提升，训练样本的增加，最终的预测平均准确率在逐渐提升。这符合我们的理论分析，说明在训练样本增加的情况下模型的确获得了更多有关垃圾邮件的信息，并最终提高了准确率。从 PR 曲线上我们也可以看到，采样率越高，使用的训练样本越多，PR曲线越好，表现在图中 PR 曲线基本是层层包含关系，基本呈现效果随训练样本的增加而变好。

    这一点也可以从最低准确率看出，因为最低准确率相当于综合考虑了模型的预测能力和模型的稳定性。这样看来，在使用全部数据后模型的最差表现最好，与我们的理论分析相同。

  * 但是如果我们只观察最高准确率，我们发现其并不严格地随着采样率的提高而提高，而是呈现了一种先上升后下降的趋势。这可能是因为我们的训练集和测试集中本身样本不是完全随机独立的。集合中垃圾邮件数量与非垃圾邮件数量大致呈 2:1 的比例，在随机采样时，我们选取到的样本有一定的随机性，导致每次提取出的特征，也就是我们最终字典的词集合，我们估计出的概率也会随之变动。在这种情况下，很有可能在某几次采样中我们可以获得很贴近于测试集的词频率，从而得到较好的结果，体现在最高准确率上。

  * 上一点的结论也可以由标准差的变化趋势看出。可以看到随着采样率的上升，结果的标准差在不断下降，说明在采样数量足够多时，最终的采样偏差会逐渐变小，结果的稳定性上升。

### 2. 零概率问题的处理

* 理论分析

  在第一部分的理论分析中，我们没有讨论如果一个测试集正文中出现的词在训练集中从未出现的情况。在这种情况下，我们基于频率的估计方法会出现将这些项估计为0的偏差，即：
  $$
  P(X_i = x_i| Y = \{spam/ham\}) \approx \frac{\# word\ x_i\ in\ all\ \{\ spam/ham\}}{\# total\ words\ in\ \{spam/ham\}\ } = 0
  $$
  显然在实际的邮件中这些单词出现的频率不是0，而一般是一个较低的频率值。上述的估计结果与理论结果是有偏的，而且在我们的简化公式中对概率的计算是以这些词的条件概率连乘的形式进行的，一个为零的项会对结果产生破坏。

  对此我们采用 Laplace 平滑的方法解决零概率问题。

  平滑的基本思想是在我们没有很好的足够的先验知识时，一般应当引入无信息的先验分布，对应在这一问题中就是假设所有的词都有一个均匀的先验分布，词出现的条件概率均相同，为一个较小的值。而不应当引入偏见，如将未出现的值的概率简单地看作是零。由此我们得到修正的经过 Laplace 平滑后的对条件概率的估计：
  $$
  P(X_i = x_i| Y = \{spam/ham\}) \approx \frac{\# word\ x_i\ in\ all\ \{\ spam/ham\}+\alpha}{\# total\ words\ in\ \{spam/ham\}+M\alpha\ }
  $$
  其中 $\alpha$ 是我们引入的均匀先验分布中每个词对应的概率，$M$ 是训练集中出现的所有词。这样处理后没有出现在训练集中的单词就具有了一个较小的先验概率，与实际情况更为符合。

* 实现方案

  在实现中我们需要解决两类零概率问题：

  * 第一类就是在训练集中从未出现过的词，在估算邮件是/不是垃圾邮件时都会出现概率为0的情况。注意到此时即使我们分配给这个词一个先验的概率，由于没有任何先验知识，我们没有理由认为这一单词 $X_i$ 的 $P(X_i|Y = spam) \not= P(X_i|Y=ham)$。所以这些词对垃圾邮件和非垃圾邮件的判断没有引入任何信息，我们选择直接剔除这些词，不考虑它们对结果产生的影响。
  * 第二类是仅在垃圾邮件集或非垃圾邮件集中出现的词。此时我们有了对这个词的先验知识，所以我们有理由认为对于该词 $X_i$ 此时有 $P(X_i|Y = spam) \not= P(X_i|Y=ham)$。此时我们的模型将会考虑这个词并分别在垃圾邮件集和非垃圾邮件集上做 Laplace 平滑。

* 实验结果

  我们采用全部的训练集数据，测试不使用平滑（系数 $\alpha$ 为0），使用不同平滑系数的 Laplace 平滑最后的模型效果。

  | 平滑系数  | 准确率     | Precision  | Recall     | F1         |
  | --------- | ---------- | ---------- | ---------- | ---------- |
  | 0         | 0.9441     | 0.9716     | 0.9417     | 0.9564     |
  | 1e-20     | 0.9714     | **0.9865** | 0.9694     | 0.9779     |
  | **1e-15** | **0.9752** | 0.9858     | **0.9760** | **0.9809** |
  | 1e-10     | 0.9744     | 0.9849     | 0.9757     | 0.9803     |
  | 1e-3      | 0.9635     | 0.9818     | 0.9618     | 0.9717     |
  | 1         | 0.9499     | 0.9762     | 0.9462     | 0.9610     |

  分析：

  可以看到不做平滑效果最差，这是因为在不做平滑时为了避免零概率只能舍弃所有可能造成零概率的词，损失了很多信息；同时在平滑时参数的选取对准确率也有很大的影响，因为我们的训练集不大，所以取较小的平滑系数能够更好地体现未出现词概率低的特征，所以这一结果是合理的。

### 3. 其他特殊 Feature 的探究

* 理论分析

  之前我们的讨论只选取了邮件正文的分词结果作为描述一个邮件是否垃圾邮件的特征，事实上我们从数据集描述中可以看到数据包含了很大一部分邮件的 metadata，我们也可以从这一部分数据中提取出一些特殊 feature 也作为描述垃圾邮件的特征，与我们之前的正文分词特征互为补充。

  观察 metadata 我们可以看到发件地址是一个比较合理的特征。因为很多邮箱是限定用户的，如清华邮箱；而有些特定的邮箱地址很可能大量发送垃圾邮件从而被我们的模型记录下来。

  综上所述，我们选择发送邮箱地址为一个特殊 feature。

* 实现方案

  首先注意到在数据集提供的 metadata 的 From 项中除了邮件地址外还有其他如发件人之类的信息，在此我只选取了邮件地址这一部分，原因在于一般用户名等信息也包含在邮箱地址中，且在 From 项中杂乱的信息很多，容易引入大量噪声，反而对最终的结果造成影响。

  对于邮件地址，我进一步用 `'@'`和 `'.'`两个符号对其进一步切分，得到更细粒度的字符段信息，以这些信息按照类似之前分词的操作进行训练和预测。

  由于在这一 feature 上仍然使用了naive bayes 的基本思想，所以我们此时也要考虑零概率问题。在这里我选择对结果不进行平滑处理，理由如下：

  * 首先，在每封邮件中邮箱地址这部分信息很少，我们在训练集中获得的信息相对较少，这种情况下我们最后获得的总特征集合可能还是不够全，导致在预测时出现平滑的概率很大，这样对最终的结果影响很大；
  * 第二，邮箱地址往往是一个很强的特征，比如如果是清华邮箱或教育邮箱（tsinghua, edu, etc.），有大概率不是垃圾邮件；而一些特殊的邮箱地址（51job, etc.）发出的邮件有大概率是垃圾邮件（当然大部分垃圾邮件还是从一些乱码邮箱地址发送的）。在这样的情况下，模型应该倾向于给在训练集中出现的词更高的权重，而相应减少没有见过的词的权重，这样的情况下不使用平滑更为合理。
  * 第三，在测试集中每个邮件中的发件邮件地址长度一般也很短，信息也很少，这种情况下如果使用平滑，对结果的概率影响很大，很容易稀释关键词的权重，影响结果。

* 实验结果

  我们使用两种方法对发件邮箱地址这一 feature 进行评价，一是指使用这一个 feature 对邮件进行分类，观察其效果；二是综合正文分词 feature 和发件邮箱地址 feature，评价综合模型的效果。

  单一发件邮箱地址 feature 预测结果：

  | 准确率 | Precision | Recall     | F1     |
  | ------ | --------- | ---------- | ------ |
  | 0.9278 | 0.9199    | **0.9741** | 0.9462 |

  综合两种 feature 后：

  * 综合两种 feature 的方法如下：

    由于直接采用概率值归一计算会由于概率相差悬殊导致结果极为接近 0 或 1，不利于进一步利用，因此直接对两种 featrue 预测的邮件为/不为垃圾邮件的概率取对数后做归一化，将归一化值求平均作为预测邮件是否为垃圾邮件的概率。这种方法保证了单调性的同时防止了数据下溢造成的信息丢失，同时较好的兼顾了两种 feature。

  * 预测结果：

  | 准确率     | Precision  | Recall | F1         |
  | ---------- | ---------- | ------ | ---------- |
  | **0.9872** | **0.9865** | 0.9694 | **0.9778** |

  分析：

  * 可以看到单一使用邮件地址 featrue 的效果已经比较不错，达到了 93% 左右，说明这一 feature 的确与邮件是否为垃圾邮件有强关联性。
  * 综合两种 feature 后模型的预测能力进一步提升，约为 99%，说明两种feature 之间能够互相补充，为对方提供额外信息，最终提高预测质量。

* 补充说明：

  实际上在数据集提供的邮件 metadata 中还有很多其他的信息，但是这些特征有的只有部分邮件有，对于训练和预测来说信息量太少且很可能有偏，因此很不适合用作 feature；而如 Date 之类的特征本身预测能力不强，很可能无法体现 spam 和 ham 的差异，也不适合。此处我们选取 Date 作为 feature验证如上分析。

  * 预测结果如下：

  | 准确率 | Precision | Recall | F1     |
  | ------ | --------- | ------ | ------ |
  | 0.6914 | 0.6723    | 0.9977 | 0.8033 |

  可以看出虽然 recall 很高，但是整体准确率和 F1 值都不高，说明 Date 的误判率较高，虽然基本能够完全判断出 spam，但在过程中将很多 ham 也误判了，整体效果不佳。

  虽然如此，但我们也可以从结果中看出 date 作为 feature 也有其特点，我们可以用 date 作为初步判断，这样可以筛掉大部分的 ham，提高检测速度，同时不会放过很多 spam，提高了整体效率。

## 四 总结

1. 我们将训练后得到的信息整理成 json，并选取其中出现频率最高的30个词，以此反映模型提取出的特征。

   * Spam

   ```
   [('的', 409236), ('公司', 84919), ('和', 58589), ('是', 58146), ('与', 56954), ('在', 54134), ('管理', 51971), ('有', 51491), ('企业', 45980), ('您', 43400), ('元', 40522), ('你',38727), ('等', 37282), ('发票', 34301), ('了', 34007), ('我', 32658), ('为', 31044), ('可以', 30278), ('人', 29036), ('或', 28637), ('有限公司', 28209), ('及', 26552), ('可', 25134), ('服务', 24988), ('本', 24391), ('月', 23206), ('我们',22469), ('合作', 22071), ('如何', 21730), ('中国', 20343)]

   ```

   * Ham

    ```
    [('的', 279853), ('我', 139007), ('了', 103075), ('是', 70467), ('他', 52405), ('你', 51285), ('在', 48705), ('不', 38257), ('也', 37948), ('她', 37663), ('就', 36654), ('都', 34056), ('说', 33436), ('和', 32158), ('有', 31984), ('很', 27962), ('人', 25127), ('一个', 24037), ('自己', 21506), ('没有', 19703), ('我们', 17042), ('好', 16748), ('对', 16373), ('要', 15694), ('还', 15252), ('去', 14502), ('会', 14106), ('给', 13486), ('什么', 13445), ('时候', 12742)]
    ```


   可以看出提取出的 spam 中的高频词有很多是具有代表性的关键词，如”发票“，”有限公司“等；

   而 ham 中的高频词主要是一些人称代词和虚词，符合我们日常交流的习惯。虽然在 spam 中也有一些人称代词，但是可以明显地看出差异。

   说明我们的模型可以较好的提取出邮件的特征。